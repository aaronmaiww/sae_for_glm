{"cells":[{"cell_type":"markdown","metadata":{"id":"7Vc5DmfEXA6U"},"source":["#Set-up"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21726,"status":"ok","timestamp":1737371886126,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"},"user_tz":0},"id":"tHCB1e3fR6Op","outputId":"c27f218f-1ecd-4879-ffba-a5518b181816"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCSNtTQhOp7q"},"outputs":[],"source":["# set seeds\n","import random\n","import numpy as np\n","import torch\n","\n","def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","\n","set_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"lg7oZQ6COCW-"},"source":["# Load NT model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRRjvfEZOCXA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734538260512,"user_tz":0,"elapsed":6907,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"5faf0248-0c7f-409c-8788-e9500d260097"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["\"loading smallest nucleotide transformer (50m params)\"\n","\n","\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","import torch\n","\n","num_params = 50 ## default 50\n","\n","# Import the tokenizer and the model\n","tokenizer_nt = AutoTokenizer.from_pretrained(f\"InstaDeepAI/nucleotide-transformer-v2-{num_params}m-multi-species\", trust_remote_code=True)\n","model_nt = AutoModelForMaskedLM.from_pretrained(f\"InstaDeepAI/nucleotide-transformer-v2-{num_params}m-multi-species\", trust_remote_code=True)"]},{"cell_type":"code","source":["!pip install -U bitsandbytes --upgrade\n","!pip install -U accelerate\n","!python -m bitsandbytes\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIdjoY9XcBZB","executionInfo":{"status":"ok","timestamp":1737371966013,"user_tz":0,"elapsed":15775,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"a11e391a-402a-4023-d82f-fbc08e2a9768"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.45.0\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n","Collecting accelerate\n","  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.27.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n","Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.2.1\n","    Uninstalling accelerate-1.2.1:\n","      Successfully uninstalled accelerate-1.2.1\n","Successfully installed accelerate-1.3.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","++++++++++++++++++ BUG REPORT INFORMATION ++++++++++++++++++\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","++++++++++++++++++++++++++ OTHER +++++++++++++++++++++++++++\n","CUDA specs: CUDASpecs(highest_compute_capability=(8, 0), cuda_version_string='121', cuda_version_tuple=(12, 1))\n","PyTorch settings found: CUDA_VERSION=121, Highest Compute Capability: (8, 0).\n","To manually override the PyTorch CUDA version please see: https://github.com/TimDettmers/bitsandbytes/blob/main/docs/source/nonpytorchcuda.mdx\n","The directory listed in your path is found to be non-existent: /sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events\n","The directory listed in your path is found to be non-existent: //172.28.0.1\n","The directory listed in your path is found to be non-existent: 8013\n","The directory listed in your path is found to be non-existent: //colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-a100-s-12yj7nb7g5bax --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true --enable_kernel_event_logging=true\n","The directory listed in your path is found to be non-existent: /datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages\n","The directory listed in your path is found to be non-existent: /env/python\n","The directory listed in your path is found to be non-existent: //ipykernel.pylab.backend_inline\n","CUDA SETUP: WARNING! CUDA runtime files not found in any environmental path.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","++++++++++++++++++++++ DEBUG INFO END ++++++++++++++++++++++\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","Checking that the library is importable and CUDA is callable...\n","SUCCESS!\n","Installation was successful!\n"]}]},{"cell_type":"code","source":["import transformers\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import bitsandbytes as bnb\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"metagene-ai/METAGENE-1-BnB-4Bit\", '_load_in_4bit')\n","from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n","\n","# Define quantization config\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=\"float16\",\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True\n",")\n","\n","# Load model with quantization config\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"metagene-ai/METAGENE-1-BnB-4Bit\",\n","    quantization_config=quantization_config,\n","    device_map=\"auto\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385,"referenced_widgets":["df495ef9b7704afeb51a0d0197ece6b4","29a9a669186b43d88fbfa0dc71c0ef1e","b7454bed565b45a8b6c9457f404fe959","0208b45794b64a1aabedbeeab991f27a","125e5bed0a2e4dd38983d9d99105bce4","192ed458aa3640bdb2c601ab6eb72d7a","cabb1d5b68ad41a0ad947a4a34965a14","6182f2de283a4785980b839cb91b706a","54a1e537482b496ea4817834c558d768","1a71b35a36e1492c81ea747b3a92c237","79a350780db44571b5d85cb521407e7f","098433481b4a4665b5bf544da5873679","a4658f9321bb4149864911ad8f8d1543","e3463def897b499dad202f477c22cdf0","e529f57df636426c886b67b12ceb1433","b0a15949fd0a4eadb112c40ac2d477c8","cc4c4b9952c54d919f0479883ab48e40","d33467356d564b718c49d49ec5f1dd11","4bf56ba099d5405e932637f3006119c6","0f24725887d7442e80649f61fe2e77f6","8f0e13d9e7ec439aa68942f5804452cb","c6b2b4d78cc84580bc84739e21c31c14","fb9644a87ae14b52a1defbe19e5ded7b","1ee2da5b5b3841c8a092b0a34d66586f","6323ac1ba1e84afb9a00999ae343190b","402acae878574f31901a89567ea25ae0","d5991c1f23c944d0a0a39e2580170331","66a88de2be88475e89c464a318d6d2db","b8ef8452635e403686572b9e456bcfb4","212a55d8c6da4ce4b26f17aeb45c7158","77170a11b16d43b6ab2294f4636a189c","a81037acdcb04d12aa95d06f4c91ec43","23651a76d4ad42439514197adf07ca3d","a1cc86d76a6c405088176c8979a92314","87b5129d625945d0b19e0b6dcbfb9e05","08cd6cbf99a641868513bb00417fc4ec","00ff58a90f0d478c9ea7dafab2b2a160","bbf2e705c4504232afdfcb52626a6c04","e805058e0fd74ec49d01d9f240a0aefb","bfe2becc79414032a0c3245402665173","5618cb8568e34a0086fceb2704f89aff","329b2e40f1fe4392b7dfe3e692673ccb","b50692ac64314fda91ea0f9aeea3003d","68b2e2f917e744dc9e01cf4845bd017b","1b2d2b32323544079d2a7867f0f90667","de012004fee6486396ba81c2aea26373","13419862776640a7aa1b42fcf95da6b8","1fa958c95ce84b2fae83d90412917891","c5581aa54f6a4292b54f13da7477c680","6a6e18501aed4bc9822631bead6558f1","d3fd4602d59840b7ab990d775142f8a7","0ca3cf7c09a640cc8f18f8f9c0537012","7f48e58551014c1e81ec9e37475a0a48","b046a30c2be84aa6b86de564e1fe7054","7d8614c7c00143488528ce533e0ea5b6","8430382c5ccc47e39507bac7b36fdd85","9ddbf50850e341e1b95f2b66b9c63f5c","be02235f8a2d4ed9a974747268ac2409","7821be58d75a4882b3d4b0533865fa65","fcd281fe0fda4d0ba9c84c9ff168ccab","92efe728b6984c468ee19df75d2af28d","2f4c0ac5973747eab286046a4fac4a0e","2353d487d6434f6ebbf3fdeebf849ea0","fb55fe2c7e064083b3e7ffd269c85ac7","a82f9df567c44c148dcaece03122cc0b","46c2ccf608cc4d70ac4f381eb6bf03cb"]},"id":"jeLdAWkvUGzt","executionInfo":{"status":"ok","timestamp":1737372060017,"user_tz":0,"elapsed":92377,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"294a4dd8-1c0b-4a59-f13d-7b98b6ab3bb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df495ef9b7704afeb51a0d0197ece6b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/41.9k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098433481b4a4665b5bf544da5873679"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/833 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb9644a87ae14b52a1defbe19e5ded7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1cc86d76a6c405088176c8979a92314"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n","  warnings.warn(warning_msg)\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/3.36G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b2d2b32323544079d2a7867f0f90667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8430382c5ccc47e39507bac7b36fdd85"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"hDnJt2lOaNNH"},"source":["# Load and preprocess addgene dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"elapsed":7365,"status":"error","timestamp":1734538224328,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"},"user_tz":0},"id":"TVB42q0l9vag","outputId":"aaa72324-a750-4a01-de00-6f051697e833"},"outputs":[{"output_type":"error","ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-a307f9b0ab4f>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."]}],"source":["import pandas as pd\n","\n","\n","# Constants\n","TEST_DATA_PATH = '/content/drive/MyDrive/NOO_paper/Datasets/WorldWide/BLAST_geac_ext_169k_val_random.csv'\n","TRAIN_DATA_PATH = '/content/drive/MyDrive/NOO_paper/Datasets/WorldWide/BLAST_geac_ext_169k_train_random.csv'\n","INFREQUENT_THRESHOLD = 10\n","\n","def split_test_data(test_data):\n","    \"\"\"Split test data into input and target variables.\"\"\"\n","    y_test = test_data['nations']\n","    x_test = test_data[['sequence']]\n","    return x_test, y_test\n","\n","def replace_infrequent_labels(labels, threshold=INFREQUENT_THRESHOLD):\n","    \"\"\"Identify and replace infrequent labels.\"\"\"\n","    label_counts = labels.value_counts()\n","    infrequent_labels = label_counts[label_counts < threshold].index\n","    return labels.replace(infrequent_labels, 'infrequent')\n","\n","def map_labels_to_integers(labels):\n","    \"\"\"Map labels to integers.\"\"\"\n","    unique_labels = labels.unique()\n","    return {label: int(i) for i, label in enumerate(unique_labels)}\n","\n","def without_US(data):\n","    \"\"\"Filter out rows where the nation is 'UNITED STATES'.\"\"\"\n","    data_wo_US = data[data['nations'] != 'UNITED STATES']\n","    data_wo_US.reset_index(drop=True, inplace=True)\n","\n","    data_w_US = data[data['nations'] == 'UNITED STATES']\n","    data_w_US.reset_index(drop=True, inplace=True)\n","    return data_wo_US, data_w_US\n","\n","def US_vs_them(labels):\n","    \"\"\"Categorize labels into 'UNITED STATES' and 'NON US'.\"\"\"\n","    return labels.apply(lambda x: x if x == 'UNITED STATES' else 'NON US')\n","\n","def pad_sequence(seq, length, pad_char='N'):\n","    \"\"\"Pad sequences to the specified length with the given character.\"\"\"\n","    return seq.ljust(length, pad_char)[:length]\n","\n","# Load data\n","train_data = pd.read_csv(TRAIN_DATA_PATH)\n","test_data = pd.read_csv(TEST_DATA_PATH)\n","\n","print(f'test_data shape: {test_data.shape}')\n","\n","# Remove US\n","# train_data, train_data_US = without_US(train_data)\n","# test_data, test_data_US = without_US(test_data)\n","\n","print(f'test_data shape: {test_data.shape}')\n","\n","# Split data\n","x_train, y_train = train_data[['sequence']], train_data['nations']\n","x_test, y_test = split_test_data(test_data)\n","\n","print(f'test_data shape: {y_test.shape}')\n","print(f'x_train shape: {x_train.shape}')\n","print(f'y_train shape: {y_train.shape}')\n","\n","# Combine labels from train and test datasets\n","processed_labels = pd.concat([y_train, y_test], axis=0, ignore_index=True)\n","label_to_int = map_labels_to_integers(processed_labels)\n","\n","\n","# map labels to integers\n","y_train = y_train.map(label_to_int)\n","y_test = y_test.map(label_to_int)\n","\n","print(f'y_test shape: {y_test.shape}')\n","\n","\n","# reset indices before concat\n","x_train.reset_index(drop=True, inplace=True)\n","y_train.reset_index(drop=True, inplace=True)\n","x_test.reset_index(drop=True, inplace=True)\n","y_test.reset_index(drop=True, inplace=True)\n","\n","df_train = pd.concat([x_train, y_train], axis=1)\n","df_val = pd.concat([x_test, y_test], axis=1)\n","\n","print(f'test_data shape: {test_data.shape}')\n","\n","\n","# Filter out sequences shorter than min_length and clean them\n","min_length = 0\n","df_train = df_train[df_train['sequence'].str.len() > min_length]\n","df_val = df_val[df_val['sequence'].str.len() > min_length]\n","\n","print(f'test_data shape: {test_data.shape}')\n","\n","\n","# Ensure indices are reset correctly\n","df_train.reset_index(drop=True, inplace=True)\n","df_val.reset_index(drop=True, inplace=True)\n","\n","# Display the split data\n","print(\"Train Data Shape:\", df_train.shape)\n","print(\"Validation Data Shape:\", df_val.shape)\n"]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","\n","class GenomicDataset(Dataset):\n","    def __init__(self,\n","                 ds: pd.DataFrame,\n","                 tokenizer_nt,\n","                 seq_length: int = 8000):\n","\n","\n","        self.sequences = ds['sequence']\n","        self.labels = ds['nations']\n","        self.seq_len = seq_length\n","        self.tokenizer = tokenizer_nt\n","\n","\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.sequences.iloc[idx]\n","        label = self.labels.iloc[idx]\n","\n","        # Tokenize the sequence\n","        inputs = self.tokenizer(sequence, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        input_ids = inputs['input_ids'].squeeze()  # Remove batch dimension\n","        attention_mask = inputs['attention_mask'].squeeze()  # Remove batch dimension\n","\n","        # to torch tensors\n","        label = torch.tensor(label, dtype=torch.long)\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'label': label\n","        }\n","\n","# Parameters\n","\n","val_dataset = GenomicDataset(df_val, tokenizer_nt=tokenizer_nt)\n","train_dataset = GenomicDataset(df_train, tokenizer_nt=tokenizer_nt)\n","\n","BS = 64\n","\n","val_loader_dna = DataLoader(val_dataset, batch_size=BS, shuffle=False, pin_memory=True, num_workers=2)\n","train_loader_dna = DataLoader(train_dataset, batch_size=BS, shuffle=True, pin_memory=True, num_workers=2)"],"metadata":{"id":"3zyQjb_RRQDP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load pretraining data of NT"],"metadata":{"id":"WzAR4hS4gTpb"}},{"cell_type":"code","source":["!pip install datasets\n","!pip install huggingface_hub\n","!pip install biopython"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OL7vUaoclmvO","executionInfo":{"status":"ok","timestamp":1737372069615,"user_tz":0,"elapsed":9602,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"6f4dbd20-02b4-41ce-cf8a-54fc60484107"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.9.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2024.12.14)\n","Collecting biopython\n","  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\n","Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: biopython\n","Successfully installed biopython-1.85\n"]}]},{"cell_type":"markdown","source":["## Multispecies"],"metadata":{"id":"WU-OHptXlSea"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from datasets import load_dataset\n","from typing import Optional\n","import numpy as np\n","from tqdm import tqdm\n","\n","\n","\n","class StreamingGenomicDataset(Dataset):\n","    def __init__(\n","        self,\n","        split: str = \"train\",\n","        tokenizer = None,\n","        seq_length: int = 512,\n","        max_samples: Optional[int] = None,\n","        cache_mode: bool = True\n","    ):\n","        \"\"\"\n","        Streaming dataset for genomic sequences.\n","\n","        Args:\n","            split: Dataset split ('train', 'validation', 'test')\n","            tokenizer: Tokenizer for DNA sequences\n","            seq_length: Maximum sequence length\n","            max_samples: Maximum number of samples to load (None for all)\n","            cache_mode: If True, caches all sequences in memory\n","        \"\"\"\n","        self.seq_length = seq_length\n","        self.tokenizer = tokenizer\n","\n","        # Load dataset in streaming mode\n","        dataset = load_dataset(\"InstaDeepAI/multi_species_genomes\", split=split, streaming=True)\n","\n","        if cache_mode:\n","            # Cache all sequences in memory\n","            self.sequences = []\n","            pbar = tqdm(dataset, total=max_samples, desc=f\"Loading {split} data\")\n","\n","            for i, item in enumerate(pbar):\n","                if max_samples and i >= max_samples:\n","                    break\n","                self.sequences.append(item)\n","        else:\n","            # Store iterator for streaming mode\n","            self.sequences = dataset\n","            self.max_samples = max_samples\n","\n","    def __len__(self):\n","        if isinstance(self.sequences, list):\n","            return len(self.sequences)\n","        return self.max_samples if self.max_samples else int(1e9)  # Large number for streaming\n","\n","    def __getitem__(self, idx):\n","        if isinstance(self.sequences, list):\n","            # Cached mode\n","            item = self.sequences[idx]\n","        else:\n","            # Streaming mode\n","            item = next(iter(self.sequences))\n","\n","        sequence = item['sequence']\n","\n","        # Tokenize the sequence\n","        inputs = self.tokenizer(\n","            sequence,\n","            max_length=self.seq_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(),\n","            'attention_mask': inputs['attention_mask'].squeeze(),\n","            'sequence_info': {\n","                'description': item['description'],\n","                'start_pos': item['start_pos'],\n","                'end_pos': item['end_pos']\n","            }\n","        }\n","\n","def create_genomic_dataloaders(\n","    tokenizer,\n","    batch_size: int = 32,\n","    seq_length: int = 512,\n","    max_samples: Optional[int] = None,\n","    num_workers: int = 2,\n","    cache_mode: bool = True\n","):\n","    \"\"\"\n","    Create training and validation DataLoaders for genomic data.\n","\n","    Args:\n","        tokenizer: DNA sequence tokenizer\n","        batch_size: Batch size for DataLoader\n","        seq_length: Maximum sequence length\n","        max_samples: Maximum samples per split (None for all)\n","        num_workers: Number of DataLoader workers\n","        cache_mode: If True, caches all sequences in memory\n","    \"\"\"\n","    # Create datasets\n","    train_dataset = StreamingGenomicDataset(\n","        split=\"train\",\n","        tokenizer=tokenizer,\n","        seq_length=seq_length,\n","        max_samples=max_samples,\n","        cache_mode=cache_mode\n","    )\n","\n","    val_dataset = StreamingGenomicDataset(\n","        split=\"validation\",\n","        tokenizer=tokenizer,\n","        seq_length=seq_length,\n","        max_samples=max_samples//10,\n","        cache_mode=cache_mode\n","    )\n","\n","    # Create dataloaders\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=cache_mode,  # Can only shuffle if data is cached\n","        num_workers=num_workers,\n","        pin_memory=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=num_workers,\n","        pin_memory=True\n","    )\n","\n","    return train_loader, val_loader\n","\n","# Example usage\n","# Create dataloaders with small sample size for testing\n","train_loader, val_loader = create_genomic_dataloaders(\n","    tokenizer=tokenizer,\n","    batch_size=32,\n","    seq_length=512,\n","    max_samples=19600,  # Small sample size for testing\n","    cache_mode=True\n",")\n","\n","# Print dataset sizes\n","print(f\"Training batches: {len(train_loader)}\")\n","print(f\"Validation batches: {len(val_loader)}\")\n","\n","# Example of iterating through one batch\n","for batch in train_loader:\n","    print(\"\\nBatch shapes:\")\n","    print(f\"Input ids: {batch['input_ids'].shape}\")\n","    print(f\"Attention mask: {batch['attention_mask'].shape}\")\n","    break\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FFCVaMwlVDi","executionInfo":{"status":"ok","timestamp":1737372161546,"user_tz":0,"elapsed":21480,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"60f3d1ac-79df-4a30-a2da-8e66ff16bb99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading train data: 100%|██████████| 19600/19600 [00:18<00:00, 1051.35it/s]\n","Loading validation data: 100%|██████████| 1960/1960 [00:01<00:00, 1191.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Training batches: 613\n","Validation batches: 62\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Batch shapes:\n","Input ids: torch.Size([32, 512])\n","Attention mask: torch.Size([32, 512])\n"]}]},{"cell_type":"code","source":["# Example of iterating through one batch\n","for batch in train_loader:\n","    print(\"\\nBatch shapes:\")\n","    print(f\"Input ids: {batch['input_ids']}\")\n","    print(f\"Attention mask: {batch['attention_mask'].shape}\")\n","    break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2T0fvL4uo1Sa","executionInfo":{"status":"ok","timestamp":1737372163281,"user_tz":0,"elapsed":458,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"cf403d3a-7ff8-4f1d-d4c1-c22d6a1eb374"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Batch shapes:\n","Input ids: tensor([[  6,  57,  64,  ...,  23,  26, 234],\n","        [941,  50,  27,  ...,  40, 116,  63],\n","        [  6, 828,  73,  ..., 491, 361,  32],\n","        ...,\n","        [157, 337,  41,  ..., 160,  58, 100],\n","        [  6,  18, 854,  ...,  84, 772,  64],\n","        [622, 453,  61,  ..., 340, 952,  25]])\n","Attention mask: torch.Size([32, 512])\n"]}]},{"cell_type":"code","source":["## test how long it takes for the model to perform forward passes on all of these"],"metadata":{"id":"-N6shnwLc2hD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Compare MLM loss on plasmids vs multi-specis"],"metadata":{"id":"JupjSgmhQPuZ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","from typing import Dict, List, Optional\n","from dataclasses import dataclass\n","\n","@dataclass\n","class MLMEvalResults:\n","    total_loss: float\n","    num_batches: int\n","    total_tokens: int\n","    masked_tokens: int\n","    per_batch_losses: List[float]\n","\n","class MatchedMLMEvaluator:\n","    def __init__(self, model, tokenizer, device='cuda'):\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.device = device\n","        self.loss_fct = nn.CrossEntropyLoss(reduction='mean')\n","\n","        # Exact hyperparameters from training\n","        self.mask_token_id = model.config.mask_token_id\n","        self.mask_ratio = 0.15\n","        self.mask_prob = 0.8\n","        self.random_token_prob = 0.1  # Changed from 0.5 to match training\n","        self.pad_token_id = model.config.pad_token_id\n","\n","    def create_mlm_mask(self, input_ids):\n","        \"\"\"\n","        Create MLM masks exactly matching training setup:\n","        - 15% of tokens selected for corruption\n","        - Of these:\n","          - 80% replaced with [MASK]\n","          - 10% replaced with random token\n","          - 10% unchanged\n","        \"\"\"\n","        probability_matrix = torch.full(input_ids.shape, self.mask_ratio, device=self.device)\n","\n","        # Don't mask padding tokens\n","        special_tokens_mask = input_ids == self.pad_token_id\n","        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n","\n","        # Select tokens for corruption\n","        corrupted_indices = torch.bernoulli(probability_matrix).bool()\n","\n","        # Prepare outputs\n","        labels = input_ids.clone()\n","        labels[~corrupted_indices] = -100  # Only compute loss on corrupted tokens\n","\n","        # Copy input_ids for masking\n","        masked_input_ids = input_ids.clone()\n","\n","        # For corrupted tokens:\n","        # - 80% [MASK]\n","        indices_mask = corrupted_indices & (torch.rand_like(probability_matrix) < self.mask_prob)\n","        masked_input_ids[indices_mask] = self.mask_token_id\n","\n","        # - 10% random token\n","        indices_random = corrupted_indices & ~indices_mask & (torch.rand_like(probability_matrix) < self.random_token_prob)\n","        random_words = torch.randint(4, self.model.config.vocab_size, labels.shape, device=self.device)\n","        masked_input_ids[indices_random] = random_words[indices_random]\n","\n","        # - 10% unchanged (already handled by not modifying those positions)\n","\n","        return masked_input_ids, labels, corrupted_indices\n","\n","    def evaluate_batch(self, batch: Dict[str, torch.Tensor]):\n","        \"\"\"Evaluate a single batch with exact training settings\"\"\"\n","        self.model.eval()\n","        with torch.no_grad():\n","            # Move batch to device\n","            input_ids = batch['input_ids'].to(self.device)\n","            attention_mask = batch.get('attention_mask', torch.ones_like(input_ids)).to(self.device)\n","\n","            # Create MLM masks\n","            masked_input_ids, labels, corrupted_indices = self.create_mlm_mask(input_ids)\n","\n","            # Forward pass\n","            outputs = self.model(\n","                input_ids=masked_input_ids,\n","                attention_mask=attention_mask\n","            )\n","\n","            # Calculate loss\n","            logits = outputs.logits\n","\n","            # Only compute loss on corrupted tokens\n","            active_logits = logits[corrupted_indices]\n","            active_labels = labels[corrupted_indices]\n","\n","            loss = self.loss_fct(\n","                active_logits.view(-1, self.model.config.vocab_size),\n","                active_labels.view(-1)\n","            )\n","\n","            return (\n","                loss.item(),\n","                corrupted_indices.sum().item(),\n","                attention_mask.sum().item()\n","            )\n","\n","    def evaluate_dataset(self, dataloader, num_batches=None):\n","        \"\"\"Evaluate entire dataset\"\"\"\n","        total_loss = 0\n","        total_tokens = 0\n","        total_masked = 0\n","        batch_losses = []\n","\n","        iterator = tqdm(dataloader) if num_batches is None else tqdm(list(islice(dataloader, num_batches)))\n","\n","        for batch in iterator:\n","            loss, num_masked, num_tokens = self.evaluate_batch(batch)\n","            total_loss += loss\n","            total_masked += num_masked\n","            total_tokens += num_tokens\n","            batch_losses.append(loss)\n","\n","        return MLMEvalResults(\n","            total_loss=total_loss,\n","            num_batches=len(batch_losses),\n","            total_tokens=total_tokens,\n","            masked_tokens=total_masked,\n","            per_batch_losses=batch_losses\n","        )\n","\n","def print_evaluation_results(name: str, results: MLMEvalResults):\n","    \"\"\"Print evaluation results\"\"\"\n","    print(f\"\\n{name} Dataset Results:\")\n","    print(\"-\" * 60)\n","    print(f\"Average Loss: {results.total_loss / results.num_batches:.4f}\")\n","    print(f\"Mask Ratio: {results.masked_tokens / results.total_tokens:.1%}\")\n","    print(f\"Total Tokens: {results.total_tokens}\")\n","    print(f\"Masked Tokens: {results.masked_tokens}\")"],"metadata":{"id":"ZeVZqLtsQSyE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize evaluator with matched hyperparameters\n","model_nt = model_nt.cuda()\n","evaluator = MatchedMLMEvaluator(model_nt, tokenizer_nt)\n","\n","# Evaluate both datasets\n","multi_results = evaluator.evaluate_dataset(train_loader, num_batches=10)\n","print_evaluation_results(\"Multi-species\", multi_results)\n","\n","addgene_results = evaluator.evaluate_dataset(train_loader_dna, num_batches=10)\n","print_evaluation_results(\"Addgene\", addgene_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrJhIiBaQUwh","executionInfo":{"status":"ok","timestamp":1734368630905,"user_tz":0,"elapsed":11212,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"e9cec03e-9175-4934-9684-968cccf11536"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:03<00:00,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Multi-species Dataset Results:\n","------------------------------------------------------------\n","Average Loss: 6.2668\n","Mask Ratio: 15.0%\n","Total Tokens: 327680\n","Masked Tokens: 49089\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 10/10 [00:03<00:00,  3.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Addgene Dataset Results:\n","------------------------------------------------------------\n","Average Loss: 6.0871\n","Mask Ratio: 14.9%\n","Total Tokens: 273280\n","Masked Tokens: 40768\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"opsr0vp1S1G8"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from typing import Dict, Optional\n","from dataclasses import dataclass\n","import numpy as np\n","\n","class MLMEvaluatorTests:\n","    def __init__(self, evaluator, model, tokenizer):\n","        \"\"\"\n","        Initialize testing suite for MLM evaluation.\n","\n","        Args:\n","            evaluator: MLMDatasetEvaluator instance\n","            model: The transformer model\n","            tokenizer: The tokenizer used\n","        \"\"\"\n","        self.evaluator = evaluator\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","    def run_all_checks(self, batch):\n","        \"\"\"Run all sanity checks on a single batch.\"\"\"\n","        results = {}\n","        print(\"Running sanity checks...\")\n","\n","        # Test 1: Check mask token application\n","        results[\"mask_check\"] = self.check_mask_application(batch)\n","\n","        # Test 2: Check loss computation\n","        results[\"loss_check\"] = self.check_loss_computation(batch)\n","\n","        # Test 3: Check attention mask handling\n","        results[\"attention_check\"] = self.check_attention_mask(batch)\n","\n","        # Test 4: Check token distributions\n","        results[\"token_dist_check\"] = self.check_token_distribution(batch)\n","\n","        # Test 5: Check model output shapes\n","        results[\"shape_check\"] = self.check_output_shapes(batch)\n","\n","        return results\n","\n","    def check_mask_application(self, batch, mask_ratio=0.15):\n","        \"\"\"Verify masking is applied correctly.\"\"\"\n","        with torch.no_grad():\n","            input_ids = batch['input_ids'].to(self.evaluator.device)\n","            masked_input_ids = input_ids.clone()\n","\n","            # Generate mask\n","            rand = torch.rand(input_ids.shape, device=self.evaluator.device)\n","            mask_arr = (rand < mask_ratio) * (input_ids != 0) * (input_ids != 1)\n","\n","            # Apply masking\n","            masked_input_ids[mask_arr] = 3  # mask token ID\n","\n","            # Compute statistics\n","            total_tokens = (input_ids != 0).sum().item()\n","            masked_tokens = mask_arr.sum().item()\n","            actual_ratio = masked_tokens / total_tokens if total_tokens > 0 else 0\n","\n","            result = {\n","                \"pass\": abs(actual_ratio - mask_ratio) < 0.05,  # Within 5% of target\n","                \"target_ratio\": mask_ratio,\n","                \"actual_ratio\": actual_ratio,\n","                \"total_tokens\": total_tokens,\n","                \"masked_tokens\": masked_tokens\n","            }\n","\n","            print(f\"\\nMask Application Check:\")\n","            print(f\"Target mask ratio: {mask_ratio:.3f}\")\n","            print(f\"Actual mask ratio: {actual_ratio:.3f}\")\n","            print(f\"Status: {'PASS' if result['pass'] else 'FAIL'}\")\n","\n","            return result\n","\n","    def check_loss_computation(self, batch):\n","        \"\"\"Verify loss computation is reasonable.\"\"\"\n","        with torch.no_grad():\n","            loss, num_masked, ratio = self.evaluator.calculate_batch_mlm_loss(batch)\n","\n","            result = {\n","                \"pass\": 0 < loss < 20,  # Reasonable range for cross-entropy loss\n","                \"loss_value\": loss,\n","                \"num_masked\": num_masked,\n","                \"ratio\": ratio\n","            }\n","\n","            print(f\"\\nLoss Computation Check:\")\n","            print(f\"Loss value: {loss:.3f}\")\n","            print(f\"Status: {'PASS' if result['pass'] else 'FAIL'}\")\n","\n","            return result\n","\n","    def check_attention_mask(self, batch):\n","        \"\"\"Verify attention mask is being properly applied.\"\"\"\n","        attention_mask = batch.get('attention_mask')\n","        if attention_mask is None:\n","            print(\"\\nAttention Mask Check: SKIP - No attention mask provided\")\n","            return {\"pass\": None, \"message\": \"No attention mask\"}\n","\n","        with torch.no_grad():\n","            # Check if mask aligns with pad tokens\n","            input_ids = batch['input_ids']\n","            pad_tokens = (input_ids == 0)\n","            mask_match = (attention_mask == 0) == pad_tokens\n","\n","            result = {\n","                \"pass\": mask_match.all().item(),\n","                \"matching_ratio\": mask_match.float().mean().item()\n","            }\n","\n","            print(f\"\\nAttention Mask Check:\")\n","            print(f\"Mask-padding alignment: {result['matching_ratio']:.3%}\")\n","            print(f\"Status: {'PASS' if result['pass'] else 'FAIL'}\")\n","\n","            return result\n","\n","    def check_token_distribution(self, batch):\n","        \"\"\"Check distribution of tokens in batch.\"\"\"\n","        input_ids = batch['input_ids']\n","\n","        # Get token counts\n","        unique_tokens, counts = torch.unique(input_ids, return_counts=True)\n","        total_tokens = input_ids.numel()\n","\n","        # Calculate distribution\n","        distribution = {\n","            self.tokenizer.convert_ids_to_tokens(t.item()):\n","            (c.item() / total_tokens)\n","            for t, c in zip(unique_tokens, counts)\n","        }\n","\n","        result = {\n","            \"pass\": len(distribution) > 1,  # Should have multiple token types\n","            \"distribution\": distribution,\n","            \"unique_tokens\": len(distribution)\n","        }\n","\n","        print(f\"\\nToken Distribution Check:\")\n","        print(f\"Unique tokens: {len(distribution)}\")\n","        print(f\"Top 5 tokens: {dict(sorted(distribution.items(), key=lambda x: x[1], reverse=True)[:5])}\")\n","        print(f\"Status: {'PASS' if result['pass'] else 'FAIL'}\")\n","\n","        return result\n","\n","    def check_output_shapes(self, batch):\n","        \"\"\"Verify model output shapes are correct.\"\"\"\n","        with torch.no_grad():\n","            input_ids = batch['input_ids'].to(self.evaluator.device)\n","            attention_mask = batch.get('attention_mask')\n","\n","            if attention_mask is not None:\n","                attention_mask = attention_mask.to(self.evaluator.device)\n","                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","            else:\n","                outputs = self.model(input_ids=input_ids)\n","\n","            # Check shapes\n","            batch_size, seq_len = input_ids.shape\n","            expected_logits_shape = (batch_size, seq_len, self.tokenizer.vocab_size)\n","\n","            result = {\n","                \"pass\": outputs.logits.shape == expected_logits_shape,\n","                \"expected_shape\": expected_logits_shape,\n","                \"actual_shape\": tuple(outputs.logits.shape)\n","            }\n","\n","            print(f\"\\nOutput Shapes Check:\")\n","            print(f\"Expected shape: {expected_logits_shape}\")\n","            print(f\"Actual shape: {tuple(outputs.logits.shape)}\")\n","            print(f\"Status: {'PASS' if result['pass'] else 'FAIL'}\")\n","\n","            return result\n","\n","def print_test_summary(test_results: Dict):\n","    \"\"\"Print summary of all test results.\"\"\"\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"MLM Evaluator Test Summary\")\n","    print(\"=\"*50)\n","\n","    all_passed = True\n","    for test_name, result in test_results.items():\n","        if result.get('pass') is not None:  # Skip tests that weren't run\n","            status = 'PASS' if result['pass'] else 'FAIL'\n","            print(f\"{test_name:<20}: {status}\")\n","            all_passed = all_passed and result['pass']\n","\n","    print(\"\\nOverall Status:\", \"PASS\" if all_passed else \"FAIL\")\n","    print(\"=\"*50)\n","\n","# Initialize evaluator and tests\n","evaluator = MLMDatasetEvaluator(model_nt)\n","test_suite = MLMEvaluatorTests(evaluator, model_nt, tokenizer_nt)\n","\n","# Run tests on a single batch from each dataset\n","print(\"\\nTesting Multi-species dataset:\")\n","for batch in train_loader:\n","    test_results = test_suite.run_all_checks(batch)\n","    print_test_summary(test_results)\n","    break\n","\n","print(\"\\nTesting Human Reference dataset:\")\n","for batch in train_loader_dna:\n","    test_results = test_suite.run_all_checks(batch)\n","    print_test_summary(test_results)\n","    break\n","\n","# If tests pass, proceed with main evaluation\n","if all(result.get('pass', False) for result in test_results.values()):\n","    print(\"\\nAll tests passed! Proceeding with main evaluation...\")\n","    dataloaders = {\n","        \"Multi-species\": train_loader,\n","        \"Human Reference\": train_loader_dna\n","    }\n","    results = evaluator.compare_datasets(dataloaders, num_batches=10)\n","    print_comparison_results(results)\n","else:\n","    print(\"\\nSome tests failed! Please check the results above.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrZxp0pJRVwN","executionInfo":{"status":"ok","timestamp":1734366339292,"user_tz":0,"elapsed":67786,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"55066fe9-ce0e-4fd2-b9d3-f7ee09f84b9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Testing Multi-species dataset:\n","Running sanity checks...\n","\n","Mask Application Check:\n","Target mask ratio: 0.150\n","Actual mask ratio: 0.151\n","Status: PASS\n","\n","Loss Computation Check:\n","Loss value: 8.035\n","Status: PASS\n","\n","Attention Mask Check:\n","Mask-padding alignment: 100.000%\n","Status: PASS\n","\n","Token Distribution Check:\n","Unique tokens: 4102\n","Top 5 tokens: {'<cls>': 0.001953125, 'CGCCGC': 0.001373291015625, 'GCGGCG': 0.00136566162109375, 'GCCGCC': 0.00131988525390625, 'GCGCCG': 0.001251220703125}\n","Status: PASS\n","\n","Output Shapes Check:\n","Expected shape: (256, 512, 4107)\n","Actual shape: (256, 512, 4107)\n","Status: PASS\n","\n","==================================================\n","MLM Evaluator Test Summary\n","==================================================\n","mask_check          : PASS\n","loss_check          : PASS\n","attention_check     : PASS\n","token_dist_check    : PASS\n","shape_check         : PASS\n","\n","Overall Status: PASS\n","==================================================\n","\n","Testing Human Reference dataset:\n","Running sanity checks...\n","\n","Mask Application Check:\n","Target mask ratio: 0.150\n","Actual mask ratio: 0.149\n","Status: PASS\n","\n","Loss Computation Check:\n","Loss value: 7.954\n","Status: PASS\n","\n","Attention Mask Check:\n","Mask-padding alignment: 100.000%\n","Status: PASS\n","\n","Token Distribution Check:\n","Unique tokens: 4103\n","Top 5 tokens: {'<unk>': 0.17136001586914062, '<cls>': 0.001953125, 'N': 0.001682281494140625, 'C': 0.0009002685546875, 'G': 0.000865936279296875}\n","Status: PASS\n","\n","Output Shapes Check:\n","Expected shape: (512, 512, 4107)\n","Actual shape: (512, 512, 4107)\n","Status: PASS\n","\n","==================================================\n","MLM Evaluator Test Summary\n","==================================================\n","mask_check          : PASS\n","loss_check          : PASS\n","attention_check     : PASS\n","token_dist_check    : PASS\n","shape_check         : PASS\n","\n","Overall Status: PASS\n","==================================================\n","\n","All tests passed! Proceeding with main evaluation...\n","\n","Evaluating dataset: Multi-species\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating Multi-species: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluating dataset: Human Reference\n"]},{"output_type":"stream","name":"stderr","text":["\n","Evaluating Human Reference: 100%|██████████| 10/10 [00:25<00:00,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","MLM Loss Comparison Results:\n","------------------------------------------------------------\n","Dataset                Avg Loss  Per Token Mask Ratio\n","------------------------------------------------------------\n","Multi-species            8.0329     0.0004    100.00%\n","Human Reference          7.9300     0.0002    100.00%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Human ref"],"metadata":{"id":"16mXRG7ZlThC"}},{"cell_type":"code","source":["# Install required packages\n","!pip install pysam pandas\n","\n","import subprocess\n","import pandas as pd\n","import pysam\n","import os\n","\n","class GenomeDataLoader:\n","    def __init__(self, data_dir=\"./genome_data\"):\n","        \"\"\"Initialize the genome data loader.\"\"\"\n","        self.data_dir = data_dir\n","        os.makedirs(data_dir, exist_ok=True)\n","\n","    def download_hg38(self):\n","        \"\"\"Download the latest human reference genome (hg38).\"\"\"\n","        print(\"Downloading hg38 reference genome...\")\n","        # Install required tools\n","        subprocess.run(\"apt-get update && apt-get install -y wget samtools\", shell=True)\n","\n","        # Download from UCSC\n","        genome_url = \"https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\"\n","        subprocess.run(f\"wget {genome_url} -P {self.data_dir}\", shell=True)\n","\n","        # Decompress\n","        subprocess.run(f\"gunzip {self.data_dir}/hg38.fa.gz\", shell=True)\n","\n","        # Index the genome\n","        subprocess.run(f\"samtools faidx {self.data_dir}/hg38.fa\", shell=True)\n","\n","        return f\"{self.data_dir}/hg38.fa\"\n","\n","    def download_1000g_vcf(self, chromosome=\"chr1\"):\n","        \"\"\"\n","        Download 1000 Genomes Project VCF for specified chromosome.\n","        \"\"\"\n","        print(f\"Downloading 1000G data for {chromosome}...\")\n","        # Install required tools\n","        subprocess.run(\"apt-get update && apt-get install -y tabix\", shell=True)\n","\n","        # Download from 1000G FTP\n","        base_url = \"http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/release/20190312_biallelic_SNV_and_INDEL\"\n","        vcf_url = f\"{base_url}/{chromosome}.vcf.gz\"\n","\n","        subprocess.run(f\"wget {vcf_url} -P {self.data_dir}\", shell=True)\n","        subprocess.run(f\"wget {vcf_url}.tbi -P {self.data_dir}\", shell=True)\n","\n","        return f\"{self.data_dir}/{chromosome}.vcf.gz\"\n","\n","    def read_reference_sequence(self, fasta_file, chromosome, start, end):\n","        \"\"\"\n","        Read a sequence from the reference genome.\n","        \"\"\"\n","        with pysam.FastaFile(fasta_file) as fasta:\n","            return fasta.fetch(chromosome, start, end)\n","\n","    def read_variants(self, vcf_file, chromosome, start, end):\n","        \"\"\"\n","        Read variants from 1000G VCF file.\n","        \"\"\"\n","        variants = []\n","        with pysam.VariantFile(vcf_file) as vcf:\n","            for record in vcf.fetch(chromosome, start, end):\n","                variants.append({\n","                    'position': record.pos,\n","                    'reference': record.ref,\n","                    'alternate': record.alts[0],\n","                    'allele_freq': record.info.get('AF', [None])[0]\n","                })\n","        return pd.DataFrame(variants)\n","\n","    def get_sequence_with_variants(self, ref_file, vcf_file, chromosome, start, end):\n","        \"\"\"\n","        Get reference sequence and its variants in the specified region.\n","        \"\"\"\n","        sequence = self.read_reference_sequence(ref_file, chromosome, start, end)\n","        variants = self.read_variants(vcf_file, chromosome, start, end)\n","\n","        return {\n","            'sequence': sequence,\n","            'variants': variants\n","        }\n","\n","def example_usage():\n","    \"\"\"Example usage of the GenomeDataLoader class.\"\"\"\n","    loader = GenomeDataLoader()\n","\n","    # Download reference genome\n","    ref_file = loader.download_hg38()\n","\n","    # Download 1000G data for chromosome 1\n","    vcf_file = loader.download_1000g_vcf(\"chr1\")\n","\n","    # Get sequence and variants for a specific region\n","    region = loader.get_sequence_with_variants(\n","        ref_file=ref_file,\n","        vcf_file=vcf_file,\n","        chromosome=\"chr1\",\n","        start=1000000,\n","        end=1001000\n","    )\n","\n","    print(\"\\nReference sequence:\")\n","    print(region['sequence'][:100] + \"...\")\n","    print(\"\\nVariants found:\")\n","    print(region['variants'].head())\n","\n","\n","\n","# Copy and paste the code above\n","# Then initialize and use:\n","loader = GenomeDataLoader()\n","ref_file = loader.download_hg38()\n","#vcf_file = loader.download_1000g_vcf(\"chr1\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"BsCpqS_SgVZ8","executionInfo":{"status":"error","timestamp":1734365737010,"user_tz":0,"elapsed":55471,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"46e74c54-60fd-4622-82d7-2561510608dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pysam\n","  Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (22.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pysam\n","Successfully installed pysam-0.22.1\n","Downloading hg38 reference genome...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-97dbebf6d5cf>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# Then initialize and use:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenomeDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mref_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_hg38\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;31m#vcf_file = loader.download_1000g_vcf(\"chr1\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-97dbebf6d5cf>\u001b[0m in \u001b[0;36mdownload_hg38\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Decompress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"gunzip {self.data_dir}/hg38.fa.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Index the genome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1960\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pysam\n","import numpy as np\n","from typing import Optional\n","\n","class Hg38Dataset(Dataset):\n","    def __init__(\n","        self,\n","        fasta_file: str,\n","        tokenizer,\n","        seq_length: int = 512,\n","        chromosomes: Optional[list] = None,\n","        stride: Optional[int] = None\n","    ):\n","        \"\"\"\n","        Dataset for hg38 reference genome sequences.\n","\n","        Args:\n","            fasta_file: Path to the hg38.fa file\n","            tokenizer: DNA tokenizer\n","            seq_length: Length of sequences to return\n","            chromosomes: List of chromosomes to use (default: chr1-22,X,Y)\n","            stride: Stride length for splitting sequences (default: seq_length)\n","        \"\"\"\n","        self.fasta_file = fasta_file\n","        self.tokenizer = tokenizer\n","        self.seq_length = seq_length\n","        self.stride = stride if stride else seq_length\n","\n","        # Initialize chromosome list\n","        if chromosomes is None:\n","            self.chromosomes = [f\"chr{i}\" for i in range(1, 23)]\n","            self.chromosomes.extend([\"chrX\", \"chrY\"])\n","        else:\n","            self.chromosomes = chromosomes\n","\n","        # Calculate number of sequences per chromosome\n","        self.sequence_indices = []\n","        with pysam.FastaFile(self.fasta_file) as fasta:\n","            for chrom in self.chromosomes:\n","                chrom_length = fasta.get_reference_length(chrom)\n","                num_sequences = (chrom_length - self.seq_length) // self.stride + 1\n","\n","                for i in range(num_sequences):\n","                    start = i * self.stride\n","                    end = start + self.seq_length\n","                    if end <= chrom_length:\n","                        self.sequence_indices.append({\n","                            'chromosome': chrom,\n","                            'start': start,\n","                            'end': end\n","                        })\n","\n","    def __len__(self):\n","        return len(self.sequence_indices)\n","\n","    def __getitem__(self, idx):\n","        # Get sequence location\n","        loc = self.sequence_indices[idx]\n","\n","        # Read sequence\n","        with pysam.FastaFile(self.fasta_file) as fasta:\n","            sequence = fasta.fetch(\n","                loc['chromosome'],\n","                loc['start'],\n","                loc['end']\n","            )\n","\n","        # Tokenize sequence\n","        inputs = self.tokenizer(\n","            sequence,\n","            max_length=self.seq_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(),\n","            'attention_mask': inputs['attention_mask'].squeeze(),\n","            'position': torch.tensor([loc['start'], loc['end']], dtype=torch.long),\n","            'chromosome': loc['chromosome']\n","        }\n","\n","def create_genome_dataloaders(\n","    fasta_file: str,\n","    tokenizer,\n","    seq_length: int = 512,\n","    batch_size: int = 32,\n","    val_chromosomes: Optional[list] = None,\n","    num_workers: int = 2\n","):\n","    \"\"\"\n","    Create train and validation dataloaders for genomic data.\n","\n","    Args:\n","        fasta_file: Path to hg38.fa file\n","        tokenizer: DNA tokenizer\n","        seq_length: Sequence length\n","        batch_size: Batch size\n","        val_chromosomes: List of chromosomes to use for validation (default: chr21, chr22)\n","        num_workers: Number of worker processes for data loading\n","    \"\"\"\n","    if val_chromosomes is None:\n","        val_chromosomes = ['chr21', 'chr22']\n","\n","    # Create list of training chromosomes (all except validation chromosomes)\n","    train_chromosomes = [f\"chr{i}\" for i in range(1, 23)]\n","    train_chromosomes.extend(['chrX', 'chrY'])\n","    train_chromosomes = [c for c in train_chromosomes if c not in val_chromosomes]\n","\n","    # Create datasets\n","    train_dataset = Hg38Dataset(\n","        fasta_file=fasta_file,\n","        tokenizer=tokenizer,\n","        seq_length=seq_length,\n","        chromosomes=train_chromosomes\n","    )\n","\n","    val_dataset = Hg38Dataset(\n","        fasta_file=fasta_file,\n","        tokenizer=tokenizer,\n","        seq_length=seq_length,\n","        chromosomes=val_chromosomes\n","    )\n","\n","    # Create dataloaders\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=num_workers,\n","        pin_memory=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=num_workers,\n","        pin_memory=True\n","    )\n","\n","    return train_loader, val_loader\n","\n","# Example usage\n","def example_usage(fasta_file, tokenizer):\n","    \"\"\"\n","    Example of how to use the dataloaders.\n","    \"\"\"\n","    train_loader, val_loader = create_genome_dataloaders(\n","        fasta_file=fasta_file,\n","        tokenizer=tokenizer,\n","        seq_length=512,\n","        batch_size=32\n","    )\n","\n","    # Print dataset sizes\n","    print(f\"Training batches: {len(train_loader)}\")\n","    print(f\"Validation batches: {len(val_loader)}\")\n","\n","    # Example of iterating through data\n","    for batch in train_loader:\n","        input_ids = batch['input_ids']  # Shape: [batch_size, seq_length]\n","        attention_mask = batch['attention_mask']  # Shape: [batch_size, seq_length]\n","        positions = batch['position']  # Shape: [batch_size, 2]\n","        chromosomes = batch['chromosome']  # List of chromosome names\n","        break\n","\n","    return input_ids.shape, attention_mask.shape\n","\n","# Create dataloaders\n","train_loader, val_loader = create_genome_dataloaders(\n","    fasta_file=\"/content/genome_data/hg38.fa\",\n","    tokenizer=tokenizer_nt,\n","    seq_length=512,  # in tokens\n","    batch_size=512    # adjust based on your GPU memory\n",")"],"metadata":{"id":"XLC3GM6rhFsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in train_loader:\n","    input_ids = batch['input_ids']  # Shape: [batch_size, seq_length]\n","    attention_mask = batch['attention_mask']  # Shape: [batch_size, seq_length]\n","    print(input_ids)\n","    break"],"metadata":{"id":"OFftySqajYqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in train_loader_dna:\n","    input_ids = batch['input_ids']  # Shape: [batch_size, seq_length]\n","    attention_mask = batch['attention_mask']  # Shape: [batch_size, seq_length]\n","    print(input_ids)\n","    break"],"metadata":{"id":"ahE-QHYjjku1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Joyny51Scape"},"source":["# Set-up & Load SAE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7J-G6cJcZ-F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","cfg = {\n","    \"seed\": 49,\n","    \"batch_size\": 4096*6,\n","    \"buffer_mult\": 384,\n","    \"lr\": 5e-5,\n","    \"num_tokens\": tokenizer_nt.vocab_size,\n","    \"d_model\": 512,\n","    \"l1_coeff\": 1e-1,\n","    \"beta1\": 0.9,\n","    \"beta2\": 0.999,\n","    \"dict_mult\": 8, # hidden_d = d_model * dict_mult\n","    \"seq_len\": 512,\n","    \"d_mlp\": 512,\n","    \"enc_dtype\":\"fp32\",\n","    \"remove_rare_dir\": False,\n","    \"total_training_steps\": 10000,\n","    \"lr_warm_up_steps\": 1000,\n","    \"device\": \"cuda\"\n","}\n","cfg[\"model_batch_size\"] = 64\n","cfg[\"buffer_size\"] = cfg[\"batch_size\"] * cfg[\"buffer_mult\"]\n","cfg[\"buffer_batches\"] = cfg[\"buffer_size\"] // cfg[\"seq_len\"]\n","\n","DTYPES = {\"fp32\": torch.float32, \"fp16\": torch.float16, \"bf16\": torch.bfloat16}\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        # HP-choices\n","        d_hidden = cfg[\"d_mlp\"] * cfg[\"dict_mult\"]\n","        d_mlp = cfg[\"d_mlp\"]\n","        self.l0_coeff = cfg.get(\"l0_coeff\", 5)\n","        self.threshold = cfg.get(\"activation_threshold\", 0.3)\n","        # Temperature for sigmoid approximation\n","        self.temperature = cfg.get(\"temperature\", 1.0)\n","        dtype = DTYPES[cfg[\"enc_dtype\"]]\n","        torch.manual_seed(cfg[\"seed\"])\n","\n","        self.W_enc = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_mlp, d_hidden, dtype=dtype)))\n","        self.W_dec = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, d_mlp, dtype=dtype)))\n","        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n","        self.b_dec = nn.Parameter(torch.zeros(d_mlp, dtype=dtype))\n","        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n","\n","        self.d_hidden = d_hidden\n","        self.to(\"cuda\")\n","\n","    def get_continuous_l0(self, x):\n","        \"\"\"\n","        Compute continuous relaxation of L0 norm using sigmoid\n","        This provides useful gradients unlike the discrete L0\n","        \"\"\"\n","        # Shifted sigmoid to approximate step function\n","        return torch.sigmoid((x.abs() - self.threshold) / self.temperature)\n","\n","    def forward(self, x):\n","        # encoding and decoding of input vec\n","        x_cent = x - self.b_dec\n","        pre_acts = x_cent @ self.W_enc + self.b_enc\n","        acts = F.relu(pre_acts)\n","\n","        # Compute continuous L0 approximation before thresholding\n","        l0_proxy = self.get_continuous_l0(acts)\n","\n","        # Apply hard threshold for forward pass --- This is actually jumprelu (I think!)\n","        acts_sparse = (acts.abs() > self.threshold).float() * acts\n","        x_reconstruct = acts_sparse @ self.W_dec + self.b_dec\n","\n","        # L2 Loss (Reconstruction Loss)\n","        l2_loss = F.mse_loss(x_reconstruct.float(), x.float(), reduction='none')\n","        l2_loss = l2_loss.sum(-1)\n","        l2_loss = l2_loss.mean()\n","\n","        # Normalized MSE for reporting\n","        nmse = torch.norm(x - x_reconstruct, p=2) / torch.norm(x, p=2)\n","\n","        # Continuous L0 loss (using sigmoid approximation)\n","        l0_loss = l0_proxy.sum(dim=1).mean()\n","\n","        # Total Loss: reconstruction + sparsity\n","        loss = l2_loss + self.l0_coeff * l0_loss\n","\n","        # For monitoring: true L0 count (not used in optimization)\n","        true_l0 = (acts_sparse.float().abs() > 0).float().sum(dim=1).mean()\n","\n","        # For monitoring: L1 loss\n","        l1_loss = acts_sparse.float().abs().sum(-1).mean()\n","\n","        return loss, x_reconstruct, acts_sparse, l2_loss, nmse, l1_loss, true_l0\n","\n","    @torch.no_grad()\n","    def remove_parallel_component_of_grads(self):\n","        W_dec_normed = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n","        W_dec_grad_proj = (self.W_dec.grad * W_dec_normed).sum(-1, keepdim=True) * W_dec_normed\n","        self.W_dec.grad -= W_dec_grad_proj\n","\n","\n","\n","sae_model = AutoEncoder(cfg)\n","sae_res = AutoEncoder(cfg)\n","sae_l10 = AutoEncoder(cfg)\n"]},{"cell_type":"markdown","metadata":{"id":"Ib8OWi9F0GSP"},"source":["## Load already-trained SAE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5686,"status":"ok","timestamp":1734368798106,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"},"user_tz":0},"id":"_egcIX_P0Nm8","outputId":"c36fac0a-8ac2-4134-b7df-186539577884"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":58}],"source":["weights_path = \"/content/drive/MyDrive/SAEs_for_Genomics/Weights/nt18.5m_sae_l10_2024-11-13.pt\"\n","state_dict = torch.load(weights_path, weights_only=True)\n","sae_l10.load_state_dict(state_dict)\n","\n","weights_path = \"/content/drive/MyDrive/SAEs_for_Genomics/Weights/nt50m_sae_+40mtokens.pt\"\n","state_dict = torch.load(weights_path, weights_only=True)\n","sae_model.load_state_dict(state_dict)\n","\n","weights_path = \"/content/drive/MyDrive/SAEs_for_Genomics/Weights/nt15m_sae_final.res_2024-11-25.pt\"\n","state_dict = torch.load(weights_path, weights_only=True)\n","sae_res.load_state_dict(state_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":469,"status":"ok","timestamp":1734368798573,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"},"user_tz":0},"id":"ynI_RTATXp9F","outputId":"b6182539-f4b4-4d6e-dc04-1e9335241b58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'utils' from '//content/drive/MyDrive/SAEs_for_Genomics/utils.py'>"]},"metadata":{},"execution_count":59}],"source":["## load custom functions from utils.py\n","\n","import sys\n","sys.path.append('//content/drive/MyDrive/SAEs_for_Genomics')\n","\n","import importlib\n","import utils\n","importlib.reload(utils)"]},{"cell_type":"markdown","source":["# Eval % of CE Loss reconstructed"],"metadata":{"id":"fUp5DjtuQRv7"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","class SAEEvaluator:\n","    def __init__(self, model, sae, layer_N=11):\n","        \"\"\"\n","        Initialize evaluator with model, SAE, and target layer number.\n","\n","        Args:\n","            model: The ESM model\n","            sae: Trained SAE model\n","            layer_N: Layer number to evaluate (default: 11)\n","        \"\"\"\n","        self.model = model\n","        self.sae = sae\n","        self.layer_N = layer_N\n","        self.original_state = {}\n","        self.loss_fct = nn.CrossEntropyLoss(reduction='mean')\n","\n","        # Hyperparameters from training\n","        self.mask_token_id = model.config.mask_token_id  # Should be 2\n","        self.pad_token_id = model.config.pad_token_id   # Should be 1\n","        self.mask_ratio = 0.15\n","        self.mask_prob = 0.8      # 80% mask token\n","        self.random_prob = 0.1    # 10% random token, 10% unchanged\n","\n","        # move to cuda\n","        self.model.to('cuda')\n","        self.sae.to('cuda')\n","\n","    def _get_target_layer(self):\n","        layer = self.model.esm.encoder.layer[self.layer_N].output\n","        return layer.dense\n","\n","    def _store_original_state(self):\n","        \"\"\"Store the original layer state.\"\"\"\n","        target_layer = self._get_target_layer()\n","        self.original_state = target_layer.state_dict()\n","\n","    def _restore_original_state(self):\n","        \"\"\"Restore the original layer state.\"\"\"\n","        target_layer = self._get_target_layer()\n","        target_layer.load_state_dict(self.original_state)\n","\n","    def _replace_activations_with_zeros(self):\n","        \"\"\"Replace layer outputs with zeros.\"\"\"\n","        target_layer = self._get_target_layer()\n","\n","        def zero_forward_hook(module, input, output):\n","            zeros = torch.zeros_like(output)\n","            # Add debug prints\n","            print(f\"Original output stats - mean: {output.mean():.3f}, std: {output.std():.3f}\")\n","            print(f\"Zeroed output stats - mean: {zeros.mean():.3f}, std: {zeros.std():.3f}\")\n","            assert torch.all(zeros == 0), \"Not all values are zero!\"\n","            return zeros\n","\n","        handle = target_layer.register_forward_hook(zero_forward_hook)\n","        return handle\n","\n","    def _replace_activations_with_reconstructions(self):\n","        \"\"\"Replace layer outputs with SAE reconstructions.\"\"\"\n","        target_layer = self._get_target_layer()\n","        def reconstruction_forward_hook(module, input, output):\n","            with torch.no_grad():\n","                loss, reconstructed, hidden, l2_loss, nmse, l1_loss, true_l0 = self.sae(output)\n","                return reconstructed\n","        handle = target_layer.register_forward_hook(reconstruction_forward_hook)\n","        return handle\n","\n","    def create_mlm_mask(self, input_ids, device='cuda'):\n","        \"\"\"\n","        Create MLM masks matching training setup:\n","        - 15% of tokens selected for masking\n","        - Of those:\n","          - 80% replaced with [MASK]\n","          - 10% replaced with random token\n","          - 10% unchanged\n","        \"\"\"\n","        probability_matrix = torch.full(input_ids.shape, self.mask_ratio, device=device)\n","\n","        # Don't mask padding tokens\n","        special_tokens_mask = input_ids == self.pad_token_id\n","        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n","\n","        # Select tokens for corruption\n","        corrupted_indices = torch.bernoulli(probability_matrix).bool()\n","\n","        # Prepare outputs\n","        labels = input_ids.clone()\n","        labels[~corrupted_indices] = -100  # Only compute loss on corrupted tokens\n","\n","        # Copy input_ids for masking\n","        masked_input_ids = input_ids.clone()\n","\n","        # For corrupted tokens:\n","        # - 80% [MASK]\n","        indices_mask = corrupted_indices & (torch.rand_like(probability_matrix) < self.mask_prob)\n","        masked_input_ids[indices_mask] = self.mask_token_id\n","\n","        # - 10% random token\n","        indices_random = corrupted_indices & ~indices_mask & (torch.rand_like(probability_matrix) < self.random_prob)\n","        random_words = torch.randint(4, self.model.config.vocab_size, labels.shape, device=device)\n","        masked_input_ids[indices_random] = random_words[indices_random]\n","\n","        # - 10% unchanged (already handled by not modifying those positions)\n","\n","        return masked_input_ids, labels, corrupted_indices\n","\n","    def calculate_mlm_loss(self, batch, device='cuda', mask_arr=None):\n","        \"\"\"Calculate MLM loss for a single batch.\"\"\"\n","        self.model.eval()\n","        with torch.no_grad():\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch.get('attention_mask', torch.ones_like(input_ids)).to(device)\n","\n","            # Create masks\n","            if mask_arr is None:\n","                masked_input_ids, labels, mask_arr = self.create_mlm_mask(input_ids, device)\n","            else:\n","                # If mask provided, use it but apply same masking strategy\n","                labels = input_ids.clone()\n","                labels[~mask_arr] = -100\n","                masked_input_ids = input_ids.clone()\n","\n","                # Apply masking strategy to selected tokens\n","                indices_mask = mask_arr & (torch.rand_like(input_ids, dtype=torch.float) < self.mask_prob)\n","                indices_random = mask_arr & ~indices_mask & (torch.rand_like(input_ids, dtype=torch.float) < self.random_prob)\n","\n","                masked_input_ids[indices_mask] = self.mask_token_id\n","                random_words = torch.randint(4, self.model.config.vocab_size, labels.shape, device=device)\n","                masked_input_ids[indices_random] = random_words[indices_random]\n","\n","            # Forward pass\n","            outputs = self.model(\n","                input_ids=masked_input_ids,\n","                attention_mask=attention_mask\n","            )\n","\n","            # Calculate loss only on masked tokens\n","            logits = outputs.logits\n","            active_loss = labels != -100\n","            active_logits = logits[active_loss]\n","            active_labels = labels[active_loss]\n","\n","            loss = self.loss_fct(\n","                active_logits.view(-1, self.model.config.vocab_size),\n","                active_labels.view(-1)\n","            )\n","\n","            return loss.item(), mask_arr\n","\n","    def calculate_percent_loss_recovered(self, batch, device='cuda'):\n","        \"\"\"Calculate percentage of loss recovered by SAE reconstruction.\"\"\"\n","        self._store_original_state()\n","\n","        # Calculate original loss and get mask\n","        ce_original, mask_arr = self.calculate_mlm_loss(batch, device)\n","        print(f\"Original CE Loss: {ce_original}\")\n","\n","        # Use same mask for zero calculation\n","        zero_handle = self._replace_activations_with_zeros()\n","        ce_zero, _ = self.calculate_mlm_loss(batch, device, mask_arr)\n","        print(f\"Zero CE Loss: {ce_zero}\")\n","        zero_handle.remove()\n","\n","        # Use same mask for reconstruction calculation\n","        reconstruction_handle = self._replace_activations_with_reconstructions()\n","        ce_reconstruction, _ = self.calculate_mlm_loss(batch, device, mask_arr)\n","        print(f\"Reconstruction CE Loss: {ce_reconstruction}\")\n","        reconstruction_handle.remove()\n","\n","        self._restore_original_state()\n","\n","        # Sanity checks\n","        if ce_zero <= ce_original:\n","            print(\"WARNING: Zero loss not higher than original loss!\")\n","            print(\"Mask percentage:\", (mask_arr.sum() / mask_arr.numel()).item())\n","\n","        percent_recovered = (1 - (ce_reconstruction - ce_original) /\n","                           (ce_zero - ce_original)) * 100 if ce_zero > ce_original else 0\n","\n","        return percent_recovered"],"metadata":{"id":"w3ucdJ_YQV6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","\n","# Initialize your model, SAE, and dataloader\n","model = model_nt\n","sae = sae_model\n","dataloader = train_loader_dna\n","\n","# Create evaluator\n","# if you have an existing instance\n","evaluator = SAEEvaluator(model, sae)\n","\n","# Calculate percent loss recovered on single batch of data_loader\n","avg_percent_recovered = 0\n","\n","for i, batch in enumerate(dataloader):\n","    if i > 10:\n","        break\n","    percent_recovered = evaluator.calculate_percent_loss_recovered(batch)\n","    avg_percent_recovered += percent_recovered\n","\n","avg_percent_recovered /= len(dataloader)\n","print(f\"Average Percent Loss Recovered: {avg_percent_recovered:.2f}%\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"G0-TAVr0WZH5","executionInfo":{"status":"error","timestamp":1734369361421,"user_tz":0,"elapsed":7463,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"771dee78-1368-46fe-b680-07475980077d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original CE Loss: 6.964635372161865\n","Original output stats - mean: 0.000, std: 0.000\n","Zeroed output stats - mean: 0.000, std: 0.000\n","Zero CE Loss: 6.96466064453125\n","Reconstruction CE Loss: 7.017735004425049\n","Original CE Loss: 6.923696517944336\n","Original output stats - mean: 0.000, std: 0.000\n","Zeroed output stats - mean: 0.000, std: 0.000\n","Zero CE Loss: 6.88441801071167\n","Reconstruction CE Loss: 6.884451389312744\n","WARNING: Zero loss not higher than original loss!\n","Mask percentage: 0.12274169921875\n","Original CE Loss: 6.979600429534912\n","Original output stats - mean: 0.000, std: 0.000\n","Zeroed output stats - mean: 0.000, std: 0.000\n","Zero CE Loss: 6.970797061920166\n","Reconstruction CE Loss: 7.051527976989746\n","WARNING: Zero loss not higher than original loss!\n","Mask percentage: 0.114990234375\n","Original CE Loss: 6.959843158721924\n","Original output stats - mean: 0.000, std: 0.000\n","Zeroed output stats - mean: 0.000, std: 0.000\n","Zero CE Loss: 6.9217352867126465\n","Reconstruction CE Loss: 7.009720802307129\n","WARNING: Zero loss not higher than original loss!\n","Mask percentage: 0.12554931640625\n","Original CE Loss: 6.858223915100098\n","Original output stats - mean: 0.000, std: 0.000\n","Zeroed output stats - mean: 0.000, std: 0.000\n","Zero CE Loss: 6.899663925170898\n","Reconstruction CE Loss: 6.930947780609131\n","Original CE Loss: 6.700916290283203\n","Original output stats - mean: 0.000, std: 0.000\n","Zeroed output stats - mean: 0.000, std: 0.000\n","Zero CE Loss: 6.720340251922607\n","Reconstruction CE Loss: 6.8413920402526855\n","Original CE Loss: 6.935035705566406\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-f04dc2703b3f>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpercent_recovered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_percent_loss_recovered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mavg_percent_recovered\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpercent_recovered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-13dcec71cdd8>\u001b[0m in \u001b[0;36mcalculate_percent_loss_recovered\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Use same mask for zero calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mzero_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_activations_with_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mce_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_mlm_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Zero CE Loss: {ce_zero}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mzero_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-13dcec71cdd8>\u001b[0m in \u001b[0;36mcalculate_mlm_loss\u001b[0;34m(self, batch, device, mask_arr)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             outputs = self.model(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species/ebe8e9ea00908a1e5a8f289d47d95bb09aac9f19/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         )\n\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m         outputs = self.esm(\n\u001b[0m\u001b[1;32m   1168\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species/ebe8e9ea00908a1e5a8f289d47d95bb09aac9f19/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         )\n\u001b[0;32m-> 1060\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species/ebe8e9ea00908a1e5a8f289d47d95bb09aac9f19/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 )\n\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    738\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species/ebe8e9ea00908a1e5a8f289d47d95bb09aac9f19/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species/ebe8e9ea00908a1e5a8f289d47d95bb09aac9f19/modeling_esm.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mattention_output_ln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output_ln\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species/ebe8e9ea00908a1e5a8f289d47d95bb09aac9f19/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1803\u001b[0;31m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-13dcec71cdd8>\u001b[0m in \u001b[0;36mzero_forward_hook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# Add debug prints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Original output stats - mean: {output.mean():.3f}, std: {output.std():.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Zeroed output stats - mean: {zeros.mean():.3f}, std: {zeros.std():.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not all values are zero!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"_dRLXjTqepyu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"shAFb9-lOVHu"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeRi_tw2dhae","outputId":"d8bbbc43-39f7-477a-b2ac-4d7c32f78cb0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734371103426,"user_tz":0,"elapsed":101137,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sae-lens\n","  Downloading sae_lens-5.2.1-py3-none-any.whl.metadata (5.2 kB)\n","Collecting transformer-lens\n","  Downloading transformer_lens-2.10.0-py3-none-any.whl.metadata (12 kB)\n","Collecting circuitsvis\n","  Downloading circuitsvis-1.43.2-py3-none-any.whl.metadata (2.3 kB)\n","Collecting automated-interpretability<1.0.0,>=0.0.5 (from sae-lens)\n","  Downloading automated_interpretability-0.0.6-py3-none-any.whl.metadata (778 bytes)\n","Collecting babe<0.0.8,>=0.0.7 (from sae-lens)\n","  Downloading babe-0.0.7-py3-none-any.whl.metadata (10 kB)\n","Collecting datasets<3.0.0,>=2.17.1 (from sae-lens)\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Collecting matplotlib<4.0.0,>=3.8.3 (from sae-lens)\n","  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.1.7)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (3.9.1)\n","Requirement already satisfied: plotly<6.0.0,>=5.19.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (5.24.1)\n","Collecting plotly-express<0.5.0,>=0.4.1 (from sae-lens)\n","  Downloading plotly_express-0.4.1-py2.py3-none-any.whl.metadata (1.7 kB)\n","Collecting pytest-profiling<2.0.0,>=1.7.0 (from sae-lens)\n","  Downloading pytest_profiling-1.8.1-py3-none-any.whl.metadata (15 kB)\n","Collecting python-dotenv<2.0.0,>=1.0.1 (from sae-lens)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (6.0.2)\n","Collecting pyzmq==26.0.0 (from sae-lens)\n","  Downloading pyzmq-26.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n","Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.4.5)\n","Requirement already satisfied: simple-parsing<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.1.6)\n","Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.46.3)\n","Collecting typer<0.13.0,>=0.12.3 (from sae-lens)\n","  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.12.2)\n","Collecting zstandard<0.23.0,>=0.22.0 (from sae-lens)\n","  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (1.1.1)\n","Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens)\n","  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n","Collecting better-abc<0.0.4,>=0.0.3 (from transformer-lens)\n","  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.8.0)\n","Collecting fancy-einsum>=0.0.3 (from transformer-lens)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens)\n","  Downloading jaxtyping-0.2.36-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (1.26.4)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.2.2)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (13.9.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.2.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.5.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.66.6)\n","Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.4.1)\n","Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.18.7)\n","Requirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.5.0)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from circuitsvis)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from circuitsvis)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from circuitsvis)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from circuitsvis)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from circuitsvis)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from circuitsvis)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from circuitsvis)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from circuitsvis)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from circuitsvis)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.18.1 (from circuitsvis)\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from circuitsvis)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.1.0 (from circuitsvis)\n","  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis) (12.6.85)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.16.1)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (0.26.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (5.9.5)\n","Collecting blobfile<3.0.0,>=2.1.1 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n","  Downloading blobfile-2.1.1-py3-none-any.whl.metadata (15 kB)\n","Collecting boostedblob<0.16.0,>=0.15.3 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n","  Downloading boostedblob-0.15.5-py3-none-any.whl.metadata (2.0 kB)\n","Collecting httpx<0.28.0,>=0.27.0 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: orjson<4.0.0,>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10.12)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.5.2)\n","Collecting tiktoken<0.7.0,>=0.6.0 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting py2store (from babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading py2store-0.1.20.tar.gz (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting graze (from babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading graze-0.1.27-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2.32.3)\n","Collecting xxhash (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.11.10)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.21.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.7)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.8.2)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (2024.9.11)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2024.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6.0.0,>=5.19.0->sae-lens) (9.0.0)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.14.4)\n","Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (1.13.1)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.17.0)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (8.3.4)\n","Collecting gprof2dot (from pytest-profiling<2.0.0,>=1.7.0->sae-lens)\n","  Downloading gprof2dot-2024.6.6-py2.py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (2.18.0)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing<0.2.0,>=0.1.6->sae-lens) (0.16)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10->transformer-lens) (1.3.0)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.1->sae-lens) (0.20.3)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.3->sae-lens) (1.5.4)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (4.25.5)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (2.19.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (1.3.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (75.1.0)\n","Collecting pycryptodomex~=3.8 (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n","  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.2.3)\n","Collecting lxml~=4.9 (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n","  Downloading lxml-4.9.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n","Collecting uvloop>=0.16.0 (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n","  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.18.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (4.0.11)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae-lens) (3.4.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.5.0)\n","Collecting dol (from graze->babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading dol-0.2.94-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens) (3.0.2)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","Collecting multiprocess (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting config2py (from py2store->babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading config2py-0.1.36-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (6.4.5)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.2.2)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2.0.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.5.0)\n","Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2.2.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (5.0.1)\n","Collecting i2 (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading i2-0.1.45-py3-none-any.whl.metadata (2.1 kB)\n","Downloading sae_lens-5.2.1-py3-none-any.whl (142 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.8/142.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyzmq-26.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (920 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.0/920.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformer_lens-2.10.0-py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading circuitsvis-1.43.2-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading automated_interpretability-0.0.6-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading babe-0.0.7-py3-none-any.whl (6.9 kB)\n","Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n","Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Downloading jaxtyping-0.2.36-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n","Downloading pytest_profiling-1.8.1-py3-none-any.whl (9.9 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boostedblob-0.15.5-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gprof2dot-2024.6.6-py2.py3-none-any.whl (34 kB)\n","Downloading graze-0.1.27-py3-none-any.whl (19 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-4.9.4-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading config2py-0.1.36-py3-none-any.whl (32 kB)\n","Downloading dol-0.2.94-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading i2-0.1.45-py3-none-any.whl (202 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: py2store\n","  Building wheel for py2store (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py2store: filename=py2store-0.1.20-py3-none-any.whl size=118410 sha256=e6980ca359a103babe807a7c9890a97867518e03c3fefadb464fecb6aafeda70\n","  Stored in directory: /root/.cache/pip/wheels/ff/40/40/fa84c63029cbb45f4f3824be4be62c6838436ad4cb264b5585\n","Successfully built py2store\n","Installing collected packages: i2, dol, better-abc, zstandard, xxhash, uvloop, triton, pyzmq, python-dotenv, pycryptodomex, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lxml, jaxtyping, gprof2dot, fsspec, fancy-einsum, dill, config2py, beartype, tiktoken, pytest-profiling, py2store, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, matplotlib, httpx, graze, blobfile, typer, circuitsvis, babe, plotly-express, boostedblob, datasets, automated-interpretability, transformer-lens, sae-lens\n","  Attempting uninstall: pyzmq\n","    Found existing installation: pyzmq 24.0.1\n","    Uninstalling pyzmq-24.0.1:\n","      Successfully uninstalled pyzmq-24.0.1\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: lxml\n","    Found existing installation: lxml 5.3.0\n","    Uninstalling lxml-5.3.0:\n","      Successfully uninstalled lxml-5.3.0\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n","    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.8.0\n","    Uninstalling matplotlib-3.8.0:\n","      Successfully uninstalled matplotlib-3.8.0\n","  Attempting uninstall: httpx\n","    Found existing installation: httpx 0.28.1\n","    Uninstalling httpx-0.28.1:\n","      Successfully uninstalled httpx-0.28.1\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.15.1\n","    Uninstalling typer-0.15.1:\n","      Successfully uninstalled typer-0.15.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\n","notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 26.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed automated-interpretability-0.0.6 babe-0.0.7 beartype-0.14.1 better-abc-0.0.3 blobfile-2.1.1 boostedblob-0.15.5 circuitsvis-1.43.2 config2py-0.1.36 datasets-2.21.0 dill-0.3.8 dol-0.2.94 fancy-einsum-0.0.3 fsspec-2024.6.1 gprof2dot-2024.6.6 graze-0.1.27 httpx-0.27.2 i2-0.1.45 jaxtyping-0.2.36 lxml-4.9.4 matplotlib-3.10.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 plotly-express-0.4.1 py2store-0.1.20 pycryptodomex-3.21.0 pytest-profiling-1.8.1 python-dotenv-1.0.1 pyzmq-26.0.0 sae-lens-5.2.1 tiktoken-0.6.0 transformer-lens-2.10.0 triton-2.1.0 typer-0.12.5 uvloop-0.21.0 xxhash-3.5.0 zstandard-0.22.0\n"]}],"source":["try:\n","    # import google.colab # type: ignore\n","    # from google.colab import output\n","    %pip install sae-lens transformer-lens circuitsvis\n","except:\n","    from IPython import get_ipython  # type: ignore\n","\n","    ipython = get_ipython()\n","    assert ipython is not None\n","    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n","    ipython.run_line_magic(\"autoreload\", \"2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uy-b3CcSOVHu","outputId":"ee334844-720e-48a4-d8c9-f01d32f358d2","executionInfo":{"status":"ok","timestamp":1734371119571,"user_tz":0,"elapsed":16149,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","import os\n","\n","from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n","\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","elif torch.backends.mps.is_available():\n","    device = \"mps\"\n","else:\n","    device = \"cpu\"\n","\n","print(\"Using device:\", device)\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","source":["\n","total_training_steps = 30_000\n","batch_size = 4096\n","total_training_tokens = total_training_steps * batch_size\n","\n","lr_warm_up_steps = 0\n","lr_decay_steps = total_training_steps // 5  # 20% of training\n","l1_warm_up_steps = total_training_steps // 20  # 5% of training\n","\n","cfg = LanguageModelSAERunnerConfig(\n","    # Data Generating Function (Model + Training Distibuion)\n","    model_name=\"togethercomputer/evo-1-8k-base\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n","    model_class_name=\"AutoModelForCausalLM\",\n","    hook_name=\"\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n","    hook_layer=10,  # Only one layer in the model.\n","    d_in=1024,  # the width of the mlp output.\n","    dataset_path=\"LongSafari/open-genome\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n","    is_dataset_tokenized=False,\n","    streaming=True,  # we could pre-download the token dataset if it was small.\n","    # SAE Parameters\n","    mse_loss_normalization=None,  # We won't normalize the mse loss,\n","    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n","    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n","    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n","    normalize_sae_decoder=False,\n","    scale_sparsity_penalty_by_decoder_norm=True,\n","    decoder_heuristic_init=True,\n","    init_encoder_as_decoder_transpose=True,\n","    normalize_activations=\"expected_average_only_in\",\n","    # Training Parameters\n","    lr=5e-5,\n","    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n","    adam_beta2=0.999,\n","    lr_scheduler_name=\"constant\",  # constant learning rate with warmup.\n","    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n","    l1_coefficient=5,  # will control how sparse the feature activations are\n","    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n","    train_batch_size_tokens=batch_size,\n","    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n","    # Activation Store Parameters\n","    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n","    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n","    store_batch_size_prompts=16,\n","    # Resampling protocol\n","    use_ghost_grads=False,  # we don't use ghost grads anymore.\n","    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n","    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n","    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n","    # WANDB\n","    log_to_wandb=False,  # always use wandb unless you are just testing code.\n","    wandb_project=\"sae_lens_tutorial\",\n","    wandb_log_frequency=30,\n","    eval_every_n_wandb_logs=20,\n","    # Misc\n","    device=device,\n","    seed=42,\n","    n_checkpoints=0,\n","    checkpoint_path=\"checkpoints\",\n","    dtype=\"float32\"\n",")\n","sparse_autoencoder = SAETrainingRunner(cfg).run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":532},"id":"DwDbT6S-ecVA","outputId":"28f89d7f-9f6c-4cea-bbb3-4e542e256119","executionInfo":{"status":"error","timestamp":1734371243251,"user_tz":0,"elapsed":3421,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}}},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The repository for togethercomputer/evo-1-8k-base contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/togethercomputer/evo-1-8k-base.\n","You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n","\n","Do you wish to run the custom code? [y/N] y\n","The repository for togethercomputer/evo-1-8k-base contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/togethercomputer/evo-1-8k-base.\n","You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n","\n","Do you wish to run the custom code? [y/N] y\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/root/.cache/huggingface/modules/transformers_modules/togethercomputer/evo-1-131k-base/78c715ab81852e02ec3b1c7e795dc7250d8c7625/positional_embeddings.py'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-04aa8ca67799>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m )\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0msparse_autoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAETrainingRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/sae_training_runner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, override_dataset, override_model, override_sae)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moverride_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             self.model = load_model(\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_class_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/load_model.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_class_name, model_name, device, model_from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         )\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_class_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"AutoModelForCausalLM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         hf_model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_from_pretrained_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         ).to(device)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_remote_code\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mclass_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             model_class = get_class_from_dynamic_module(\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0mclass_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_revision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_revision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_class_in_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_in_module\u001b[0;34m(class_name, module_path, force_reload)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# Hash the module file and all its relative imports to check if we need to reload it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mmodule_files\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodule_file\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_relative_import_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mmodule_hash\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_relative_import_files\u001b[0;34m(module_file)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mnew_imports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_to_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mnew_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_relative_imports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_relative_imports\u001b[0;34m(module_file)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0mimports\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/huggingface/modules/transformers_modules/togethercomputer/evo-1-131k-base/78c715ab81852e02ec3b1c7e795dc7250d8c7625/positional_embeddings.py'"]}]},{"cell_type":"code","source":["!pip install evo-model\n","#pip install flash_attn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kT1XzYfKk2MO","executionInfo":{"status":"ok","timestamp":1734371236822,"user_tz":0,"elapsed":4396,"user":{"displayName":"TraceBioworks","userId":"04879227828096158740"}},"outputId":"a030e57d-33a2-4602-cea5-e7e02e056763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting evo-model\n","  Downloading evo_model-0.2.1-py3-none-any.whl.metadata (7.8 kB)\n","Collecting stripedhyena==0.2.2 (from evo-model)\n","  Downloading stripedhyena-0.2.2-py3-none-any.whl.metadata (19 kB)\n","Collecting biopython (from evo-model)\n","  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evo-model) (2.2.2)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from evo-model) (2.1.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from stripedhyena==0.2.2->evo-model) (4.46.3)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from stripedhyena==0.2.2->evo-model) (0.20.3)\n","Requirement already satisfied: flash-attn>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stripedhyena==0.2.2->evo-model) (2.7.2.post1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython->evo-model) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evo-model) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evo-model) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evo-model) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton->evo-model) (3.16.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn>=2.0.0->stripedhyena==0.2.2->evo-model) (2.5.1+cu121)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn>=2.0.0->stripedhyena==0.2.2->evo-model) (0.8.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evo-model) (1.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->stripedhyena==0.2.2->evo-model) (0.26.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->stripedhyena==0.2.2->evo-model) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->stripedhyena==0.2.2->evo-model) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->stripedhyena==0.2.2->evo-model) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->stripedhyena==0.2.2->evo-model) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->stripedhyena==0.2.2->evo-model) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->stripedhyena==0.2.2->evo-model) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->stripedhyena==0.2.2->evo-model) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->stripedhyena==0.2.2->evo-model) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->stripedhyena==0.2.2->evo-model) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->stripedhyena==0.2.2->evo-model) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->stripedhyena==0.2.2->evo-model) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->stripedhyena==0.2.2->evo-model) (2024.8.30)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn>=2.0.0->stripedhyena==0.2.2->evo-model) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn>=2.0.0->stripedhyena==0.2.2->evo-model) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn>=2.0.0->stripedhyena==0.2.2->evo-model) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash-attn>=2.0.0->stripedhyena==0.2.2->evo-model) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn>=2.0.0->stripedhyena==0.2.2->evo-model) (3.0.2)\n","Downloading evo_model-0.2.1-py3-none-any.whl (20 kB)\n","Downloading stripedhyena-0.2.2-py3-none-any.whl (30 kB)\n","Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: biopython, stripedhyena, evo-model\n","Successfully installed biopython-1.84 evo-model-0.2.1 stripedhyena-0.2.2\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["7Vc5DmfEXA6U","lg7oZQ6COCW-","hDnJt2lOaNNH","WzAR4hS4gTpb","opsr0vp1S1G8","16mXRG7ZlThC"],"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1tGbfVC4F3QpGoSD1EuUpcH0YHaDhb3xq","timestamp":1737372220098},{"file_id":"1_9mfNL_c2vZXHEIyWOfN3thHp4OYYrRT","timestamp":1734538744552},{"file_id":"18RDGgnMP2x_FL06iPBZ5mkhlJuIP-3-h","timestamp":1734013364535}],"mount_file_id":"18RDGgnMP2x_FL06iPBZ5mkhlJuIP-3-h","authorship_tag":"ABX9TyMVBqiawsW52+du23Rp7gZ8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"df495ef9b7704afeb51a0d0197ece6b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29a9a669186b43d88fbfa0dc71c0ef1e","IPY_MODEL_b7454bed565b45a8b6c9457f404fe959","IPY_MODEL_0208b45794b64a1aabedbeeab991f27a"],"layout":"IPY_MODEL_125e5bed0a2e4dd38983d9d99105bce4"}},"29a9a669186b43d88fbfa0dc71c0ef1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_192ed458aa3640bdb2c601ab6eb72d7a","placeholder":"​","style":"IPY_MODEL_cabb1d5b68ad41a0ad947a4a34965a14","value":"tokenizer_config.json: 100%"}},"b7454bed565b45a8b6c9457f404fe959":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6182f2de283a4785980b839cb91b706a","max":1376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54a1e537482b496ea4817834c558d768","value":1376}},"0208b45794b64a1aabedbeeab991f27a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a71b35a36e1492c81ea747b3a92c237","placeholder":"​","style":"IPY_MODEL_79a350780db44571b5d85cb521407e7f","value":" 1.38k/1.38k [00:00&lt;00:00, 93.1kB/s]"}},"125e5bed0a2e4dd38983d9d99105bce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"192ed458aa3640bdb2c601ab6eb72d7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cabb1d5b68ad41a0ad947a4a34965a14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6182f2de283a4785980b839cb91b706a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54a1e537482b496ea4817834c558d768":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a71b35a36e1492c81ea747b3a92c237":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a350780db44571b5d85cb521407e7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"098433481b4a4665b5bf544da5873679":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4658f9321bb4149864911ad8f8d1543","IPY_MODEL_e3463def897b499dad202f477c22cdf0","IPY_MODEL_e529f57df636426c886b67b12ceb1433"],"layout":"IPY_MODEL_b0a15949fd0a4eadb112c40ac2d477c8"}},"a4658f9321bb4149864911ad8f8d1543":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc4c4b9952c54d919f0479883ab48e40","placeholder":"​","style":"IPY_MODEL_d33467356d564b718c49d49ec5f1dd11","value":"tokenizer.json: 100%"}},"e3463def897b499dad202f477c22cdf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bf56ba099d5405e932637f3006119c6","max":41916,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f24725887d7442e80649f61fe2e77f6","value":41916}},"e529f57df636426c886b67b12ceb1433":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f0e13d9e7ec439aa68942f5804452cb","placeholder":"​","style":"IPY_MODEL_c6b2b4d78cc84580bc84739e21c31c14","value":" 41.9k/41.9k [00:00&lt;00:00, 3.07MB/s]"}},"b0a15949fd0a4eadb112c40ac2d477c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc4c4b9952c54d919f0479883ab48e40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d33467356d564b718c49d49ec5f1dd11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bf56ba099d5405e932637f3006119c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f24725887d7442e80649f61fe2e77f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f0e13d9e7ec439aa68942f5804452cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b2b4d78cc84580bc84739e21c31c14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb9644a87ae14b52a1defbe19e5ded7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ee2da5b5b3841c8a092b0a34d66586f","IPY_MODEL_6323ac1ba1e84afb9a00999ae343190b","IPY_MODEL_402acae878574f31901a89567ea25ae0"],"layout":"IPY_MODEL_d5991c1f23c944d0a0a39e2580170331"}},"1ee2da5b5b3841c8a092b0a34d66586f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66a88de2be88475e89c464a318d6d2db","placeholder":"​","style":"IPY_MODEL_b8ef8452635e403686572b9e456bcfb4","value":"special_tokens_map.json: 100%"}},"6323ac1ba1e84afb9a00999ae343190b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_212a55d8c6da4ce4b26f17aeb45c7158","max":833,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77170a11b16d43b6ab2294f4636a189c","value":833}},"402acae878574f31901a89567ea25ae0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a81037acdcb04d12aa95d06f4c91ec43","placeholder":"​","style":"IPY_MODEL_23651a76d4ad42439514197adf07ca3d","value":" 833/833 [00:00&lt;00:00, 70.1kB/s]"}},"d5991c1f23c944d0a0a39e2580170331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66a88de2be88475e89c464a318d6d2db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8ef8452635e403686572b9e456bcfb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"212a55d8c6da4ce4b26f17aeb45c7158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77170a11b16d43b6ab2294f4636a189c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a81037acdcb04d12aa95d06f4c91ec43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23651a76d4ad42439514197adf07ca3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1cc86d76a6c405088176c8979a92314":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87b5129d625945d0b19e0b6dcbfb9e05","IPY_MODEL_08cd6cbf99a641868513bb00417fc4ec","IPY_MODEL_00ff58a90f0d478c9ea7dafab2b2a160"],"layout":"IPY_MODEL_bbf2e705c4504232afdfcb52626a6c04"}},"87b5129d625945d0b19e0b6dcbfb9e05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e805058e0fd74ec49d01d9f240a0aefb","placeholder":"​","style":"IPY_MODEL_bfe2becc79414032a0c3245402665173","value":"config.json: 100%"}},"08cd6cbf99a641868513bb00417fc4ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5618cb8568e34a0086fceb2704f89aff","max":1326,"min":0,"orientation":"horizontal","style":"IPY_MODEL_329b2e40f1fe4392b7dfe3e692673ccb","value":1326}},"00ff58a90f0d478c9ea7dafab2b2a160":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b50692ac64314fda91ea0f9aeea3003d","placeholder":"​","style":"IPY_MODEL_68b2e2f917e744dc9e01cf4845bd017b","value":" 1.33k/1.33k [00:00&lt;00:00, 116kB/s]"}},"bbf2e705c4504232afdfcb52626a6c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e805058e0fd74ec49d01d9f240a0aefb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfe2becc79414032a0c3245402665173":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5618cb8568e34a0086fceb2704f89aff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329b2e40f1fe4392b7dfe3e692673ccb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b50692ac64314fda91ea0f9aeea3003d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68b2e2f917e744dc9e01cf4845bd017b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b2d2b32323544079d2a7867f0f90667":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de012004fee6486396ba81c2aea26373","IPY_MODEL_13419862776640a7aa1b42fcf95da6b8","IPY_MODEL_1fa958c95ce84b2fae83d90412917891"],"layout":"IPY_MODEL_c5581aa54f6a4292b54f13da7477c680"}},"de012004fee6486396ba81c2aea26373":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a6e18501aed4bc9822631bead6558f1","placeholder":"​","style":"IPY_MODEL_d3fd4602d59840b7ab990d775142f8a7","value":"model.safetensors: 100%"}},"13419862776640a7aa1b42fcf95da6b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ca3cf7c09a640cc8f18f8f9c0537012","max":3358530852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f48e58551014c1e81ec9e37475a0a48","value":3358530852}},"1fa958c95ce84b2fae83d90412917891":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b046a30c2be84aa6b86de564e1fe7054","placeholder":"​","style":"IPY_MODEL_7d8614c7c00143488528ce533e0ea5b6","value":" 3.36G/3.36G [01:19&lt;00:00, 41.3MB/s]"}},"c5581aa54f6a4292b54f13da7477c680":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a6e18501aed4bc9822631bead6558f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3fd4602d59840b7ab990d775142f8a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ca3cf7c09a640cc8f18f8f9c0537012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f48e58551014c1e81ec9e37475a0a48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b046a30c2be84aa6b86de564e1fe7054":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d8614c7c00143488528ce533e0ea5b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8430382c5ccc47e39507bac7b36fdd85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ddbf50850e341e1b95f2b66b9c63f5c","IPY_MODEL_be02235f8a2d4ed9a974747268ac2409","IPY_MODEL_7821be58d75a4882b3d4b0533865fa65"],"layout":"IPY_MODEL_fcd281fe0fda4d0ba9c84c9ff168ccab"}},"9ddbf50850e341e1b95f2b66b9c63f5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92efe728b6984c468ee19df75d2af28d","placeholder":"​","style":"IPY_MODEL_2f4c0ac5973747eab286046a4fac4a0e","value":"generation_config.json: 100%"}},"be02235f8a2d4ed9a974747268ac2409":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2353d487d6434f6ebbf3fdeebf849ea0","max":132,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb55fe2c7e064083b3e7ffd269c85ac7","value":132}},"7821be58d75a4882b3d4b0533865fa65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a82f9df567c44c148dcaece03122cc0b","placeholder":"​","style":"IPY_MODEL_46c2ccf608cc4d70ac4f381eb6bf03cb","value":" 132/132 [00:00&lt;00:00, 11.8kB/s]"}},"fcd281fe0fda4d0ba9c84c9ff168ccab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92efe728b6984c468ee19df75d2af28d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f4c0ac5973747eab286046a4fac4a0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2353d487d6434f6ebbf3fdeebf849ea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb55fe2c7e064083b3e7ffd269c85ac7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a82f9df567c44c148dcaece03122cc0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46c2ccf608cc4d70ac4f381eb6bf03cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}